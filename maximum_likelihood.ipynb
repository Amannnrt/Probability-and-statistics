{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5add4da5-786c-4181-8b34-ca51058a38cb",
   "metadata": {},
   "source": [
    "# Understanding Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "Maximum Likelihood Estimation (MLE) is a method for estimating the parameters of a statistical model. Given a dataset and a probability distribution, the goal of MLE is to find the parameter values (e.g., mean $( \\mu )$ and standard deviation $( \\sigma )$ that maximize the likelihood of observing the given data.\n",
    "\n",
    "## Key Concepts\n",
    "- **Likelihood Function**: The likelihood function is the joint probability of observing the data, treated as a function of the parameters.\n",
    "- **Log-Likelihood**: To simplify calculations, we often work with the log-likelihood because it converts products into sums and is easier to differentiate.\n",
    "\n",
    "## Likelihood Function for a Normal Distribution\n",
    "$$\n",
    "L(\\mu, \\sigma \\mid x) = \\prod_{i=1}^{n} f(x_i \\mid \\mu, \\sigma)\n",
    "$$\n",
    "\n",
    "where:\n",
    "$\n",
    "f(x_i \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}}\n",
    "$\n",
    "\n",
    "## Log-Likelihood Function\n",
    "Taking the logarithm:\n",
    "$\n",
    "\\ell(\\mu, \\sigma \\mid x) = -\\frac{n}{2} \\log (2\\pi) - \\frac{n}{2} \\log (\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0371f1-a834-4b82-a354-75fa285bcb59",
   "metadata": {},
   "source": [
    "![likelihood vs log likelihood](image1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd5a80b-1b88-436a-ab3c-29e36d62c2d5",
   "metadata": {},
   "source": [
    "**image taken from statquest YT channel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0b1c0-feaf-47e0-941a-9e4c98d7df39",
   "metadata": {},
   "source": [
    "# Finding the Maximum Likelihood Estimates (MLEs)\n",
    "\n",
    "To find the MLEs analytically, we differentiate the log-likelihood function with respect to the parameters \\( \\mu \\) and \\( \\sigma \\), set the derivatives to zero, and solve.\n",
    "\n",
    "Given a dataset $( x_1, x_2, \\dots, x_n )$ sampled from a normal distribution $( \\mathcal{N}(\\mu, \\sigma^2) )$, the likelihood function is:\n",
    "\n",
    "$$\n",
    "L(\\mu, \\sigma | x) = \\prod_{i=1}^{n} f(x_i | \\mu, \\sigma)\n",
    "$$\n",
    "\n",
    "where the probability density function (PDF) of the normal distribution is:\n",
    "\n",
    "$\n",
    "f(x_i | \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}}\n",
    "$\n",
    "\n",
    "Taking the **log-likelihood**:\n",
    "\n",
    "$\n",
    "\\ell(\\mu, \\sigma | x) = \\sum_{i=1}^{n} \\log f(x_i | \\mu, \\sigma)\n",
    "$\n",
    "\n",
    "Expanding the terms:\n",
    "\n",
    "$\n",
    "\\ell(\\mu, \\sigma | x) = -\\frac{n}{2} \\log (2\\pi) - n \\log \\sigma - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "![lmage2](image2.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Finding the MLE for \\( \\mu \\)\n",
    "To find the MLE for \\( \\mu \\), we take the derivative of the log-likelihood with respect to $( \\mu )$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial \\mu} = \\frac{1}{\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu) = 0\n",
    "$$\n",
    "\n",
    "Solving for $( \\mu )$:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (x_i - \\mu) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "Thus, the **MLE for $( \\mu )$** is:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "which is simply the **sample mean**.\n",
    "\n",
    "---\n",
    "\n",
    "## Finding the MLE for \\( \\sigma \\)\n",
    "To find the MLE for \\( \\sigma \\), we differentiate the log-likelihood with respect to $( \\sigma )$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial \\sigma} = -\\frac{n}{\\sigma} + \\frac{1}{\\sigma^3} \\sum_{i=1}^{n} (x_i - \\mu)^2 = 0\n",
    "$$\n",
    "\n",
    "Rearranging:\n",
    "\n",
    "$$\n",
    "\\sigma^3 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "Taking the square root:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_{MLE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2}\n",
    "$$\n",
    "\n",
    "which is the **sample standard deviation** with a divisor of \\( n \\) (not \\( n-1 \\), which is used in unbiased variance estimation).\n",
    "\n",
    "---\n",
    "\n",
    "for a more detailed derivation i suggest to go to this link : [MLE in case of normal distribution](https://medium.com/@lorenzojcducv/maximum-likelihood-for-the-normal-distribution-966df16fd031)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd14a23f-a561-4136-a069-107c67306b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
