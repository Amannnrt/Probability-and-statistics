{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78092467-56ce-4ac8-b2e7-6001d10b6adc",
   "metadata": {},
   "source": [
    "# Bernoulli Distribution\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with exactly two possible outcomes: success (usually denoted as 1) and failure (usually denoted as 0). It is characterized by a single parameter \\( p \\), which represents the probability of success.\n",
    "\n",
    "## Probability Mass Function (PMF)\n",
    "\n",
    "If \\( X \\) is a random variable following a Bernoulli distribution, its PMF is given by:\n",
    "\n",
    "$$\n",
    "P(X = x) =\n",
    "\\begin{cases}\n",
    "p, & \\text{if } x = 1 \\ (\\text{success}), \\\\\n",
    "1 - p, & \\text{if } x = 0 \\ (\\text{failure}).\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This can also be written compactly as:\n",
    "\n",
    "$$\n",
    "P(X = x) = p^x (1 - p)^{1 - x}, \\quad \\text{for } x \\in \\{0, 1\\}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Derivation of the Mean  $E[X]$\n",
    "\n",
    "The mean (or expected value) of a random variable \\( X \\) is defined as:\n",
    "\n",
    "$$\n",
    "E[X] = \\sum_x x \\cdot P(X = x).\n",
    "$$\n",
    "\n",
    "For the Bernoulli distribution, \\( x \\) can take only two values: 0 and 1. Substituting these values into the formula:\n",
    "\n",
    "$$\n",
    "E[X] = \\sum_{x=0}^1 x \\cdot P(X = x).\n",
    "$$\n",
    "\n",
    "Expanding the summation:\n",
    "\n",
    "$$\n",
    "E[X] = (0 \\cdot P(X = 0)) + (1 \\cdot P(X = 1)).\n",
    "$$\n",
    "\n",
    "Substitute \\( P(X = 0) = 1 - p \\) and \\( P(X = 1) = p \\):\n",
    "\n",
    "$$\n",
    "E[X] = (0 \\cdot (1 - p)) + (1 \\cdot p).\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "E[X] = 0 + p = p.\n",
    "$$\n",
    "\n",
    "Thus, the mean of a Bernoulli random variable is:\n",
    "\n",
    "$$\n",
    "E[X] = p.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Derivation of the Variance $ \\text{Var}(X) $\n",
    "\n",
    "The variance of a random variable \\( X \\) is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = E[X^2] - (E[X])^2.\n",
    "$$\n",
    "\n",
    "### Step 1: Compute $ E[X^2] $\n",
    "\n",
    "The second moment $ E[X^2] $ is given by:\n",
    "\n",
    "$$\n",
    "E[X^2] = \\sum_x x^2 \\cdot P(X = x).\n",
    "$$\n",
    "\n",
    "For the Bernoulli distribution, \\( x \\) can take only two values: 0 and 1. Substituting these values:\n",
    "\n",
    "$$\n",
    "E[X^2] = (0^2 \\cdot P(X = 0)) + (1^2 \\cdot P(X = 1)).\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "E[X^2] = (0 \\cdot (1 - p)) + (1 \\cdot p).\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "E[X^2] = p.\n",
    "$$\n",
    "\n",
    "### Step 2: Compute  $ E[X])^2 $\n",
    "\n",
    "From the earlier derivation, we know that:\n",
    "\n",
    "$$\n",
    "E[X] = p.\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "(E[X])^2 = p^2.\n",
    "$$\n",
    "\n",
    "### Step 3: Substitute into the Variance Formula\n",
    "\n",
    "Using the variance formula:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = E[X^2] - (E[X])^2.\n",
    "$$\n",
    "\n",
    "Substitute $  E[X^2] = p $  and  $ E[X]^2 = p^2 $:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = p - p^2.\n",
    "$$\n",
    "\n",
    "Factorize:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = p(1 - p).\n",
    "$$\n",
    "\n",
    "Thus, the variance of a Bernoulli random variable is:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = p(1 - p).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# Beta Distribution\n",
    "\n",
    "The Beta distribution is a continuous probability distribution defined on the interval \\([0, 1]\\). It is widely used in Bayesian statistics and in modeling probabilities or proportions. The Beta distribution is characterized by two shape parameters, typically denoted as \\( \\alpha > 0 \\) and \\( \\beta > 0 \\). These parameters control the shape of the distribution.\n",
    "\n",
    "## Probability Density Function (PDF)\n",
    "\n",
    "The PDF of the Beta distribution is given by:\n",
    "\n",
    "$$\n",
    "f(x; \\alpha, \\beta) =\n",
    "\\begin{cases}\n",
    "\\frac{x^{\\alpha - 1}(1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)}, & \\text{if } 0 \\leq x \\leq 1, \\\\\n",
    "0, & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where \\( B(\\alpha, \\beta) \\) is the Beta function, which ensures that the total probability integrates to 1. The Beta function is defined as:\n",
    "\n",
    "$$\n",
    "B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1} (1 - t)^{\\beta - 1} dt.\n",
    "$$\n",
    "\n",
    "The Beta function can also be expressed in terms of the Gamma function \\( \\Gamma \\):\n",
    "\n",
    "$$\n",
    "B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Derivation of the Mean \\( E[X] \\)\n",
    "\n",
    "The mean of a random variable \\( X \\) following a Beta distribution is given by:\n",
    "\n",
    "$$\n",
    "E[X] = \\int_0^1 x f(x; \\alpha, \\beta) dx.\n",
    "$$\n",
    "\n",
    "Substitute the PDF \\( f(x; \\alpha, \\beta) = \\frac{x^{\\alpha - 1}(1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)} \\):\n",
    "\n",
    "$$\n",
    "E[X] = \\int_0^1 x \\cdot \\frac{x^{\\alpha - 1}(1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)} dx.\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{1}{B(\\alpha, \\beta)} \\int_0^1 x^\\alpha (1 - x)^{\\beta - 1} dx.\n",
    "$$\n",
    "\n",
    "This integral is recognized as a Beta function \\( B(\\alpha + 1, \\beta) \\):\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{B(\\alpha + 1, \\beta)}{B(\\alpha, \\beta)}.\n",
    "$$\n",
    "\n",
    "Using the relationship between Beta and Gamma functions:\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{\\frac{\\Gamma(\\alpha + 1) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta + 1)}}{\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}}.\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{\\Gamma(\\alpha + 1)}{\\Gamma(\\alpha)} \\cdot \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha + \\beta + 1)}.\n",
    "$$\n",
    "\n",
    "Using the property \\( \\Gamma(\\alpha + 1) = \\alpha \\Gamma(\\alpha) \\):\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{\\alpha}{\\alpha + \\beta}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Derivation of the Variance $ \\text{Var}(X) $\n",
    "\n",
    "The variance of a Beta random variable \\( X \\) is given by:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = E[X^2] - (E[X])^2.\n",
    "$$\n",
    "\n",
    "### Step 1: Compute \\( E[X^2] \\)\n",
    "\n",
    "Following similar steps as above, \\( E[X^2] \\) involves evaluating:\n",
    "\n",
    "$$\n",
    "E[X^2] = \\frac{B(\\alpha + 2, \\beta)}{B(\\alpha, \\beta)}.\n",
    "$$\n",
    "\n",
    "Using properties of Beta and Gamma functions, this simplifies to:\n",
    "\n",
    "$$\n",
    "E[X^2] = \\frac{\\alpha (\\alpha + 1)}{(\\alpha + \\beta)(\\alpha + \\beta + 1)}.\n",
    "$$\n",
    "\n",
    "### Step 2: Substitute and Simplify\n",
    "\n",
    "Using \\( E[X] = \\frac{\\alpha}{\\alpha + \\beta} \\):\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = \\frac{\\alpha (\\alpha + 1)}{(\\alpha + \\beta)(\\alpha + \\beta + 1)} - \\left( \\frac{\\alpha}{\\alpha + \\beta} \\right)^2.\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14001840-e185-4113-b920-209a808a2c7b",
   "metadata": {},
   "source": [
    "# Conjugacy of the Bernoulli and Beta Distributions\n",
    "\n",
    "In Bayesian statistics, **conjugacy** refers to a situation where the prior distribution and the posterior distribution belong to the same family of distributions. The Bernoulli distribution (likelihood) and the Beta distribution (prior) form a conjugate pair. This makes Bayesian inference particularly elegant because the posterior distribution retains the same functional form as the prior.\n",
    "\n",
    "---\n",
    "\n",
    "## Intuition Behind Conjugacy\n",
    "\n",
    "### Bernoulli Likelihood\n",
    "\n",
    "A Bernoulli random variable $ X \\sim \\text{Bernoulli}(p) $ models binary outcomes (success/failure), where $ p $ is the probability of success.\n",
    "\n",
    "The likelihood function for observing $ n $ independent Bernoulli trials with outcomes $ x_1, x_2, \\ldots, x_n $, where $ x_i \\in \\{0, 1\\} $, is proportional to:\n",
    "\n",
    "$$\n",
    "P(x_1, x_2, \\ldots, x_n \\mid p) \\propto p^{\\text{number of successes}} (1 - p)^{\\text{number of failures}}.\n",
    "$$\n",
    "\n",
    "Let:\n",
    "- $ s = \\sum_{i=1}^n x_i $ represent the total number of successes.\n",
    "- $ f = n - s $ represent the total number of failures.\n",
    "\n",
    "Thus, the likelihood function becomes:\n",
    "\n",
    "$$\n",
    "P(x_1, x_2, \\ldots, x_n \\mid p) = p^s (1 - p)^f,\n",
    "$$\n",
    "\n",
    "where $ s $ is the number of successes and $ f $ is the number of failures.\n",
    "\n",
    "---\n",
    "\n",
    "### Beta Prior\n",
    "\n",
    "The Beta distribution is defined on the interval $ [0, 1] $, making it a natural choice for modeling probabilities (like $ p $). \n",
    "\n",
    "A Beta prior $ p \\sim \\text{Beta}(\\alpha, \\beta) $ encodes prior beliefs about $ p $ through its shape parameters $ \\alpha > 0 $ and $ \\beta > 0 $. \n",
    "\n",
    "The PDF of the Beta distribution is:\n",
    "\n",
    "$$\n",
    "P(p) = \\frac{1}{B(\\alpha, \\beta)} p^{\\alpha - 1} (1 - p)^{\\beta - 1},\n",
    "$$\n",
    "\n",
    "where $$ B(\\alpha, \\beta) $$ is the Beta function, defined as:\n",
    "\n",
    "$$\n",
    "B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1} (1 - t)^{\\beta - 1} dt.\n",
    "$$\n",
    "\n",
    "It can also be expressed in terms of the Gamma function $$ \\Gamma(\\cdot) $$:\n",
    "\n",
    "$$\n",
    "B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Derivation: Posterior Distribution\n",
    "\n",
    "### Step 1: Write the Prior\n",
    "\n",
    "The prior distribution for $ p $ is:\n",
    "\n",
    "$$\n",
    "P(p) = \\frac{1}{B(\\alpha, \\beta)} p^{\\alpha - 1} (1 - p)^{\\beta - 1}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Write the Likelihood\n",
    "\n",
    "Suppose we observe $ n $ independent Bernoulli trials with outcomes $ x_1, x_2, \\ldots, x_n $, where $ x_i \\in \\{0, 1\\} $. Let $ s = \\sum_{i=1}^n x_i $ represent the total number of successes, and $ f = n - s $ represent the total number of failures.\n",
    "\n",
    "The likelihood function for $ p $ given the data is:\n",
    "\n",
    "$$\n",
    "P(x_1, x_2, \\ldots, x_n \\mid p) = p^s (1 - p)^f.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Combine Prior and Likelihood\n",
    "\n",
    "Using **Bayes' theorem**, the posterior distribution is proportional to the product of the prior and the likelihood:\n",
    "\n",
    "$$\n",
    "P(p \\mid x_1, x_2, \\ldots, x_n) \\propto P(p) \\cdot P(x_1, x_2, \\ldots, x_n \\mid p).\n",
    "$$\n",
    "\n",
    "Substitute the expressions for the prior and likelihood:\n",
    "\n",
    "$$\n",
    "P(p \\mid x_1, x_2, \\ldots, x_n) \\propto \\left[ \\frac{1}{B(\\alpha, \\beta)} p^{\\alpha - 1} (1 - p)^{\\beta - 1} \\right] \\cdot \\left[ p^s (1 - p)^f \\right].\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "P(p \\mid x_1, x_2, \\ldots, x_n) \\propto p^{\\alpha - 1 + s} (1 - p)^{\\beta - 1 + f}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Identify the Posterior Distribution\n",
    "\n",
    "The resulting expression:\n",
    "\n",
    "$$\n",
    "P(p \\mid x_1, x_2, \\ldots, x_n) \\propto p^{\\alpha + s - 1} (1 - p)^{\\beta + f - 1}\n",
    "$$\n",
    "\n",
    "is proportional to the PDF of a Beta distribution with updated parameters:\n",
    "\n",
    "$$\n",
    "p \\mid x_1, x_2, \\ldots, x_n \\sim \\text{Beta}(\\alpha + s, \\beta + f).\n",
    "$$\n",
    "\n",
    "Thus, the posterior distribution is also a Beta distribution, with updated shape parameters:\n",
    "\n",
    "$$\n",
    "\\alpha_{\\text{posterior}} = \\alpha + s, \\quad \\beta_{\\text{posterior}} = \\beta + f.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Intuition Behind Conjugacy\n",
    "\n",
    "The property of retaining the same distributional form after updating the parameters is called **conjugacy**. This simplifies Bayesian inference significantly because it allows us to update our prior beliefs in a straightforward way after observing data.\n",
    "\n",
    "In this case, the Beta distribution is the **conjugate prior** of the Bernoulli distribution:\n",
    "\n",
    "- The prior starts as $ \\text{Beta}(\\alpha, \\beta) $.\n",
    "- After observing $ s $ successes and $ f $failures, the posterior becomes $$ \\text{Beta}(\\alpha + s, \\beta + f) $$.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Prior**: $ p \\sim \\text{Beta}(\\alpha, \\beta) $\n",
    "- **Likelihood**: $ P(x_1, x_2, \\ldots, x_n \\mid p) = p^s (1 - p)^f $\n",
    "- **Posterior**: $p \\mid x_1, x_2, \\ldots, x_n \\sim \\text{Beta}(\\alpha + s, \\beta + f) $.\n",
    "\n",
    "This conjugacy relationship makes Bayesian updates efficient and elegant, especially when dealing with Bernoulli or binomial data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab936704-c4d5-430a-9948-5f46992c9676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
